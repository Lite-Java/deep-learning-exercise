# 卷积神经网络（上）

## 一、列举两个尺寸不同的矩阵（如5X5 和 3X3），手算二者的卷积

5X5的矩阵A：

​								1 2 3 4 5

​								5 4 3 2 1 

​								2 1 3 4 5

​								3 2 4 1 5

​								4 5 3 2 1

3X3的矩阵B：

​								1 2 3

​								3 1 2

​								3 2 1

A*B计算过程：

首先将B翻转180度：1 2 3   

​                                    2 1 3

​				    3 2 1

将B在A上滑动，计算得：48 50 59

​					    53 48 54

​                                            58 53 64

## 二、给出p19中y^n的其他三个元素的计算公式

$$
y_{12}^{n}=r_{12}w_{22}^{n}+r_{13}w_{21}^{n}+r_{22}w_{12}^{n}+r_{23}w_{11}^{n}+\\
g_{12}v_{22}^{n}+g_{13}v_{21}^{n}+g_{22}v_{12}^{n}+g_{23}v_{11}^{n}+\\b_{12}u_{22}^{n}+b_{13}u_{21}^{n}+b_{22}u_{12}^{n}+b_{23}u_{11}^{n}
$$

$$
y_{21}^{n}=r_{21}w_{22}^{n}+r_{22}w_{21}^{n}+r_{31}w_{12}^{n}+r_{32}w_{11}^{n}+\\
g_{21}v_{22}^{n}+g_{22}v_{21}^{n}+g_{31}v_{12}^{n}+g_{32}v_{11}^{n}+\\b_{21}u_{22}^{n}+b_{22}u_{21}^{n}+b_{31}u_{12}^{n}+b_{32}u_{11}^{n}
$$

$$
y_{22}^{n}=r_{22}w_{22}^{n}+r_{23}w_{21}^{n}+r_{32}w_{12}^{n}+r_{33}w_{11}^{n}+\\
g_{22}v_{22}^{n}+g_{23}v_{21}^{n}+g_{32}v_{12}^{n}+g_{33}v_{11}^{n}+\\b_{22}u_{22}^{n}+b_{23}u_{21}^{n}+b_{32}u_{12}^{n}+b_{33}u_{11}^{n}
$$

## 三、从R-CNN到Fast R-CNN以及Faster R-CNN的关键改进

RCNN
　　1.	在图像中确定约1000-2000个候选框 (使用选择性搜索)
　　2. 每个候选框内图像块缩放至相同大小，并输入到CNN内进行特征提取 
　　3.	对候选框中提取出的特征，使用分类器判别是否属于一个特定类 
　　4.	对于属于某一特征的候选框，用回归器进一步调整其位置

Fast RCNN
　　1.	在图像中确定约1000-2000个候选框 (使用选择性搜索)
　　2.	对整张图片输进CNN，得到feature map
　　3.	找到每个候选框在feature map上的映射patch，将此patch作为每个候选框的卷积特征输入到SPP layer和之后的层
　　4.	对候选框中提取出的特征，使用分类器判别是否属于一个特定类 
　　5.	对于属于某一特征的候选框，用回归器进一步调整其位置

Faster RCNN
　　1.	对整张图片输进CNN，得到feature map
　　2.	卷积特征输入到RPN，得到候选框的特征信息
　　3.	对候选框中提取出的特征，使用分类器判别是否属于一个特定类 

　　4.	对于属于某一特征的候选框，用回归器进一步调整其位置

## 四、DeconvNet和SegNet的主要区别

SegNet相比于Conv-Deconv模型，最大区别在于去掉了中间7*7的池化

## 五 P51的模型中，C2层的一个节点对应到输入图像的感受野是多大？

假设第i层上对第j层的局部感受野为F(i,j),显然i>=j.假定输入层为第0层。

则现在问题转化为求F(i,0)的问题。F(i,i)=1,现只需要求出F(i,j) 与F(i,j-1)层的关系，即可通过F(i,i)求出F(i,0).

 通过简单情况和画图分析，可得出递归关系式，F(i,j-1) = kernel_size_j + (F(i,j)-1)*stride_j，kernel_size_j表示的第j层的kernel_size,stride_j表示第j层的stride.



# 卷积神经网络（下)

##  一、编程实现softmax函数（实现最基本功能即可，不需要复杂的数据结构），并与caffe源代码中的softmax层进行对比。

```
def transform_softmax(x):
    max_of_dim1 =np.max(x,axis=1,keepdims=True)#求每一行的最大值
    return (np.exp(x-max_of_dim1)/np.exp(x-max_of_dim1).sum(axis=1,keepdims=True))#每一行减去最大值
```

注意点：在softmax函数的分子分母中都有exp函数的身影，当exp函数的输入过大时，会导致在有限精度无法表示的情况，即常见的inf符号，在输入数据没有做过归一化的情况下，某一个特征的取值范围跨度很大时，其实极为容易发生上述情况。而变换处理方法其实也很简单，只需要在分子分母的exp项输入时减去某个值即可，最常用的是行方向上的最大值。即：
$$
softmax(x)=\frac{exp(x^{(i)}-max(x^{(i)}))}{\sum_{i=1}^{n}exp(x^{(i)}-max(x^{(i)}))}
$$
通过上述方法变换后的值跟原始值是一致的（分子分母同时乘以一个数可以约去）。

## 二、BN层应该位于网络的什么位置？为什么？

位于Activation激活层前面。

原因：一般来说，如果模型的输入特征不相关且满足标准正态分布![N(0, 1)](http://www.zhihu.com/equation?tex=N%280%2C+1%29)时，模型的表现一般较好。在训练神经网络模型时，我们可以事先将特征去相关并使得它们满足一个比较好的分布，这样，模型的第一层网络一般都会有一个比较好的输入特征，但是随着模型的层数加深，网络的非线性变换使得每一层的结果变得相关了，且不再满足![N(0, 1)](http://www.zhihu.com/equation?tex=N%280%2C+1%29)分布。更糟糕的是，可能这些隐藏层的特征分布已经发生了偏移。论文的作者认为上面的问题会使得神经网络的训练变得困难，为了解决这个问题，他们提出在Activation激活层前面加入Batch Normalization层。训练时，BN层利用隐藏层输出结果的均值![\mu_\mathcal{B}](http://www.zhihu.com/equation?tex=%5Cmu_%5Cmathcal%7BB%7D)与方差![\sigma^2_\mathcal{B}](http://www.zhihu.com/equation?tex=%5Csigma%5E2_%5Cmathcal%7BB%7D)来标准化每一层特征的分布，并且维护所有mini-batch数据的均值与方差，最后利用样本的均值与方差的无偏估计量用于测试时使用。鉴于在某些情况下非标准化分布的层特征可能是最优的，标准化每一层的输出特征反而会使得网络的表达能力变得不好，作者为BN层加上了两个可学习的缩放参数![\gamma](http://www.zhihu.com/equation?tex=%5Cgamma)和偏移参数![\beta](http://www.zhihu.com/equation?tex=%5Cbeta)来允许模型自适应地去调整层特征分布。

## 三、卷积核的形状和尺寸由哪些因素来确定

卷积核形状：1、一般的卷积核都是规则的K*K的正方形

​        		2、如果为了增加高层节点的实际感受野可以用“孔洞”卷积核

​			3、如果对元素位置也进行学习，采用不规则形状的卷积核

卷积核的尺寸：1、图像原始尺寸和目标尺寸

​			    2、高层节点的实际感受野

​			    3、为了获得特定尺寸的输出特征图而设定

​			    4、为了检测不同尺度、不同类型的特征，多种尺寸混合使用

​			    5、有时为了不需限制输入尺寸以及改变特征图数目（如降维）用1*1的卷积

## 四、Inception Module中包含的各个层的作用分别是什么？

inception结构的主要贡献有两个：一是使用1x1的卷积来进行升降维；二是在多个尺寸上同时进行卷积再聚合。 

1X1卷积的作用：在相同尺寸的感受野中叠加更多的卷积，能提取到更丰富的特征。 使用1x1卷积进行降维，降低了计算复杂度 

多个尺寸上进行卷积再聚合：传统的卷积层的输入数据只和一种尺度（比如3x3）的卷积核进行卷积，输出固定维度（比如256个特征）的数据，所有256个输出特征基本上是均匀分布在3x3尺度范围上，这可以理解成输出了一个稀疏分布的特征集；而inception模块在多个尺度上提取特征（比如1x1，3x3，5x5），输出的256个特征就不再是均匀分布，而是相关性强的特征聚集在一起（比如1x1的的96个特征聚集在一起，3x3的96个特征聚集在一起，5x5的64个特征聚集在一起），这可以理解成多个密集分布的子特征集。这样的特征集中因为相关性较强的特征聚集在了一起，不相关的非关键特征就被弱化，同样是输出256个特征，inception方法输出的特征“冗余”的信息较少。用这样的“纯”的特征集层层传递最后作为反向计算的输入，自然收敛的速度更快。 在inception模块中有一个分支使用了max pooling，作者认为pooling也能起到提取特征的作用，所以也加入模块中 。